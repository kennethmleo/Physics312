{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mall\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m path \u001b[39m=\u001b[39m untar_data(URLs\u001b[39m.\u001b[39mIMDB)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.text.all import *\n",
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_text_files(path, folders = ['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once again Mr. Costner has dragged out a movie for far longer than necessary.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = files[0].open().read(); txt[:77]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#15) ['Once','again','Mr.','Costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.']\n"
     ]
    }
   ],
   "source": [
    "#| label: word-tokenizer\n",
    "#| code-fold: true\n",
    "spacy = WordTokenizer()\n",
    "toks = first(spacy([txt[:77]]))\n",
    "print(coll_repr(toks, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#9) ['The','U.S.','dollar','$','1','is','$','1.00','.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(spacy(['The U.S. dollar $1 is $1.00.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.','xxmaj','aside','from','the','terrific','sea','rescue','sequences',',','of','which'...]\n"
     ]
    }
   ],
   "source": [
    "tkn = Tokenizer(spacy)\n",
    "print(coll_repr(tkn(txt), 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function fastai.text.core.fix_html(x)>,\n",
       " <function fastai.text.core.replace_rep(t)>,\n",
       " <function fastai.text.core.replace_wrep(t)>,\n",
       " <function fastai.text.core.spec_add_spaces(t)>,\n",
       " <function fastai.text.core.rm_useless_spaces(t)>,\n",
       " <function fastai.text.core.replace_all_caps(t)>,\n",
       " <function fastai.text.core.replace_maj(t)>,\n",
       " <function fastai.text.core.lowercase(t, add_bos=True, add_eos=False)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaults.text_proc_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_repr(tkn('&copy;   Fast.ai www.fast.ai/INDEX'), 31)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subword Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = L(o.open().read() for o in files[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword(sz):\n",
    "    sp = SubwordTokenizer(vocab_sz=sz)\n",
    "    sp.setup(txts)\n",
    "    return ' '.join(first(sp([txt]))[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁O n ce ▁again ▁M r . ▁Co st n er ▁has ▁ d ra g g ed ▁out ▁a ▁movie ▁for ▁far ▁long er ▁than ▁ ne ce s s ar y . ▁A side ▁from ▁the ▁ ter'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁ O n ce ▁a g a in ▁ M r . ▁ C o s t n er ▁ h a s ▁ d ra g g ed ▁ o u t ▁a ▁movie ▁for ▁f ar ▁ l'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁On ce ▁again ▁Mr . ▁Costner ▁has ▁dragged ▁out ▁a ▁movie ▁for ▁far ▁longer ▁than ▁necessary . ▁A side ▁from ▁the ▁terrific ▁sea ▁rescue ▁sequences , ▁of ▁which ▁there ▁are ▁very ▁few ▁I ▁just ▁did ▁not ▁care ▁about ▁any ▁of'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subword(10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numericalization with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.','xxmaj','aside','from','the','terrific','sea','rescue','sequences',',','of','which'...]\n"
     ]
    }
   ],
   "source": [
    "toks = tkn(txt)\n",
    "print(coll_repr(tkn(txt), 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#207) ['xxbos','xxmaj','once','again','xxmaj','mr','.','xxmaj','costner','has'...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks200 = txts[:200].map(tkn)\n",
    "toks200[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(#1968) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the','.',',','a','and','of','to','is','it','i','in'...]\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "coll_repr(num.vocab,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorText([   2,    8,  349,  183,    8, 1177,   10,    8, 1178,   60, 1455,\n",
       "              62,   12,   25,   28,  189,  957,   93,  958,   10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = num(toks)[:20]; nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj once again xxmaj mr . xxmaj costner has dragged out a movie for far longer than necessary .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(num.vocab[o] for o in nums)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting Our Texts into Batches for a Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n",
      "WeasyPrint could not import some external libraries. Please carefully follow the installation steps before reporting an issue:\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#installation\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#troubleshooting \n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot load library 'gobject-2.0-0': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'gobject-2.0-0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kenneth\\Documents\\GitHub\\Physics312\\nlp_beginners.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Kenneth/Documents/GitHub/Physics312/nlp_beginners.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mweasyprint\u001b[39;00m \u001b[39mimport\u001b[39;00m HTML\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kenneth/Documents/GitHub/Physics312/nlp_beginners.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#hide_input\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kenneth/Documents/GitHub/Physics312/nlp_beginners.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mIn this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we\u001b[39m\u001b[39m'\u001b[39m\u001b[39mll have another example of the PreProcessor used in the data block API.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mThen we will study how we build a language model and train it for a while.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\weasyprint\\__init__.py:341\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m'\u001b[39m, string, base_url, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39m# Work around circular imports.\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcss\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_stylesheet  \u001b[39m# noqa isort:skip\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhtml\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa isort:skip\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     HTML5_UA_COUNTER_STYLE, HTML5_UA_STYLESHEET, HTML5_UA_FORM_STYLESHEET,\n\u001b[0;32m    344\u001b[0m     HTML5_PH_STYLESHEET)\n\u001b[0;32m    345\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdocument\u001b[39;00m \u001b[39mimport\u001b[39;00m Document, Page  \u001b[39m# noqa isort:skip\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\weasyprint\\css\\__init__.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m LOGGER, PROGRESS_LOGGER\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39murls\u001b[39;00m \u001b[39mimport\u001b[39;00m URLFetchingError, get_url_attribute, url_join\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m computed_values, counters, media_queries\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mproperties\u001b[39;00m \u001b[39mimport\u001b[39;00m INHERITED, INITIAL_NOT_COMPUTED, INITIAL_VALUES\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_url, remove_whitespace\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\weasyprint\\css\\computed_values.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtinycss2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolor3\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_color\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m LOGGER\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mffi\u001b[39;00m \u001b[39mimport\u001b[39;00m ffi, pango, units_to_double\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mline_break\u001b[39;00m \u001b[39mimport\u001b[39;00m Layout, first_line_metrics\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39murls\u001b[39;00m \u001b[39mimport\u001b[39;00m get_link_attribute\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\weasyprint\\text\\ffi.py:428\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[39mwith\u001b[39;00m suppress((\u001b[39mOSError\u001b[39;00m, \u001b[39mFileNotFoundError\u001b[39;00m)):\n\u001b[0;32m    426\u001b[0m             os\u001b[39m.\u001b[39madd_dll_directory(dll_directory)\n\u001b[1;32m--> 428\u001b[0m gobject \u001b[39m=\u001b[39m _dlopen(\n\u001b[0;32m    429\u001b[0m     ffi, \u001b[39m'\u001b[39;49m\u001b[39mgobject-2.0-0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgobject-2.0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlibgobject-2.0-0\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    430\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mlibgobject-2.0.so.0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlibgobject-2.0.dylib\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m'\u001b[39;49m\u001b[39mlibgobject-2.0-0.dll\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    431\u001b[0m pango \u001b[39m=\u001b[39m _dlopen(\n\u001b[0;32m    432\u001b[0m     ffi, \u001b[39m'\u001b[39m\u001b[39mpango-1.0-0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpango-1.0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibpango-1.0-0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibpango-1.0.so.0\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    433\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlibpango-1.0.dylib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibpango-1.0-0.dll\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    434\u001b[0m harfbuzz \u001b[39m=\u001b[39m _dlopen(\n\u001b[0;32m    435\u001b[0m     ffi, \u001b[39m'\u001b[39m\u001b[39mharfbuzz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mharfbuzz-0.0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibharfbuzz-0\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    436\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlibharfbuzz.so.0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibharfbuzz.so.0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlibharfbuzz.0.dylib\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    437\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlibharfbuzz-0.dll\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\weasyprint\\text\\ffi.py:417\u001b[0m, in \u001b[0;36m_dlopen\u001b[1;34m(ffi, *names)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39m# Re-raise the exception.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[0;32m    409\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m-----\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    410\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mWeasyPrint could not import some external libraries. Please \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfirst_steps.html#troubleshooting\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    416\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-----\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m \u001b[39mreturn\u001b[39;00m ffi\u001b[39m.\u001b[39;49mdlopen(names[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\cffi\\api.py:150\u001b[0m, in \u001b[0;36mFFI.dlopen\u001b[1;34m(self, name, flags)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdlopen(name): name must be a file name, None, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mor an already-opened \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvoid *\u001b[39m\u001b[39m'\u001b[39m\u001b[39m handle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    149\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 150\u001b[0m     lib, function_cache \u001b[39m=\u001b[39m _make_ffi_library(\u001b[39mself\u001b[39;49m, name, flags)\n\u001b[0;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_caches\u001b[39m.\u001b[39mappend(function_cache)\n\u001b[0;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libraries\u001b[39m.\u001b[39mappend(lib)\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\cffi\\api.py:832\u001b[0m, in \u001b[0;36m_make_ffi_library\u001b[1;34m(ffi, libname, flags)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_ffi_library\u001b[39m(ffi, libname, flags):\n\u001b[0;32m    831\u001b[0m     backend \u001b[39m=\u001b[39m ffi\u001b[39m.\u001b[39m_backend\n\u001b[1;32m--> 832\u001b[0m     backendlib \u001b[39m=\u001b[39m _load_backend_lib(backend, libname, flags)\n\u001b[0;32m    833\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39maccessor_function\u001b[39m(name):\n",
      "File \u001b[1;32mc:\\Users\\Kenneth\\.julia\\conda\\3\\lib\\site-packages\\cffi\\api.py:827\u001b[0m, in \u001b[0;36m_load_backend_lib\u001b[1;34m(backend, name, flags)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m first_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    826\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.  Additionally, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (first_error, msg)\n\u001b[1;32m--> 827\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mload_library(path, flags)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot load library 'gobject-2.0-0': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'gobject-2.0-0'"
     ]
    }
   ],
   "source": [
    "from weasyprint import HTML\n",
    "\n",
    "#hide_input\n",
    "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
    "tokens = tkn(stream)\n",
    "bs,seq_len = 6,15\n",
    "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False,header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
