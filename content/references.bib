@incollection{DOBIGEON2016185,
title = {Chapter 6 - Linear and Nonlinear Unmixing in Hyperspectral Imaging},
editor = {Cyril Ruckebusch},
series = {Data Handling in Science and Technology},
publisher = {Elsevier},
volume = {30},
pages = {185-224},
year = {2016},
booktitle = {Resolving Spectral Mixtures},
issn = {0922-3487},
doi = {https://doi.org/10.1016/B978-0-444-63638-6.00006-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780444636386000061},
author = {N. Dobigeon and Y. Altmann and N. Brun and S. Moussaoui},
keywords = {Hyperspectral imagery, Spectral unmixing, Endmember extraction, Abundance estimation},
abstract = {Mainly due to the limited spatial resolution of the data acquisition devices, hyperspectral image pixels generally result from the mixture of several components that are present in the observed surface. Spectral mixture analysis (or spectral unmixing) is a key processing step which aims at identifying the spectral signatures of these materials and quantifying their spatial distribution over the image. The main purpose of this chapter is to introduce the spectral unmixing problem and to discuss some linear and nonlinear models and algorithms used to solve it. We will show that, capitalizing on several decades of methodological developments in the geoscience and remote sensing community, most of the unmixing algorithms proposed to unmix remotely sensed images can be directly applied in the chemometrics field to process hyperspectral data arising from various scanning microscopic techniques such as scanning transmission electron microscopy and Raman imaging.}
}

@INPROCEEDINGS{8080725,
  author={Heylen, Rob and Scheunders, Paul},
  booktitle={2013 5th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)}, 
  title={Multi-dimensional pixel purity index}, 
  year={2013},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/WHISPERS.2013.8080725}}

@misc{NA_2022, 
title={Pareto task inference (parti) method}, 
howpublished ={https://www.weizmann.ac.il/mcb/UriAlon/download/ParTI}, 
journal={Uri Alon}, author={N/A, N/A}, year={2022}, month={Mar}} 

@article{Chang_2005, title={Orthogonal subspace projection (OSP) revisited: A comprehensive study and analysis}, volume={43}, DOI={10.1109/tgrs.2004.839543}, number={3}, journal={IEEE Transactions on Geoscience and Remote Sensing}, author={Chang, Chein-I}, year={2005}, month={Mar}, pages={502–518}} 

@inproceedings{Cricri_spp, title={Extracting voting patterns across three Philippine senate elections using hyperspectral unmixing}, volume={38}, booktitle={Proceedings of the Samahang Pisika ng Pilipinas}, author={de Castro, Crizzia Mielle Mariano and Lim, May Tan}, year={2020}, pages={SPP-2020-2A-06}, url={https://proceedings.spp-online.org/article/view/SPP-2020-2A-06} }

@misc{wang2020contextual,
      title={Contextual Temperature for Language Modeling}, 
      author={Pei-Hsin Wang and Sheng-Iou Hsieh and Shih-Chieh Chang and Yu-Ting Chen and Jia-Yu Pan and Wei Wei and Da-Chang Juan},
      year={2020},
      eprint={2012.13575},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{holtzman2020curious,
      title={The Curious Case of Neural Text Degeneration}, 
      author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
      year={2020},
      eprint={1904.09751},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Penke_2022b, title={A mathematician’s introduction to transformers and large language models}, url={https://x-dev.pages.jsc.fz-juelich.de/2022/07/13/transformers-matmul.html}, journal={JSC Accelerating Devices Lab}, publisher={Online}, author={Penke, Carolin}, year={2022}, month={Jul}} 

@inbook{Howard_Gugger_2021, place={Sebastopol, CA}, title={Chapter 10, NLP}, booktitle={Deep learning for coders with FASTAI and pytorch: AI applications without a Phd}, publisher={O’Reilly Media, Inc.}, author={Howard, Jeremy and Gugger, Sylvain}, year={2021}} 

@misc{Olah_2015, title={Understanding LSTM networks}, url={https://colah.github.io/posts/2015-08-Understanding-LSTMs/}, journal={Understanding LSTM Networks -- colah’s blog}, author={Olah, Christopher}, year={2015}} 
@misc{vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{antimatter15_2022, title={Antimatter15/alpaca.cpp: Locally run an instruction-tuned chat-style LLM}, url={https://github.com/antimatter15/alpaca.cpp}, journal={GitHub}, author={antimatter15, antimatter15}, year={2022}}

@misc{sohldickstein2015deep,
      title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics}, 
      author={Jascha Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and Surya Ganguli},
      year={2015},
      eprint={1503.03585},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{song2020generative,
      title={Generative Modeling by Estimating Gradients of the Data Distribution}, 
      author={Yang Song and Stefano Ermon},
      year={2020},
      eprint={1907.05600},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ho2020denoising,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Ananthaswamy_2023, title={The physics principle that inspired modern AI art}, url={https://www.quantamagazine.org/the-physics-principle-that-inspired-modern-ai-art-20230105/}, journal={Quanta Magazine}, publisher={Quanta Magazine}, author={Ananthaswamy, Anil}, year={2023}, month={Feb}} 

@misc{Jmkernes_2022, title={Diffusion/diffusion/DDPM at main · JMKERNES/Diffusion}, url={https://github.com/Jmkernes/Diffusion/tree/main/diffusion/ddpm}, journal={GitHub}, author={Jmkernes, Jmkernes}, year={2022}} 

@misc{Face_2022, title={Stable diffusion 2-1 - a hugging face space by Stabilityai}, url={https://huggingface.co/spaces/stabilityai/stable-diffusion}, journal={Stable Diffusion 2-1 - a Hugging Face Space by stabilityai}, publisher={Hugging Face}, author={Face, Hugging}, year={2022}} 