<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kenneth Leo">

<title>Physics 312 - Advanced Mathematical Physics II - Language Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../content/diffusion.html" rel="next">
<link href="../index.html" rel="prev">
<link href="../images/favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Language Models</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Physics 312 - Advanced Mathematical Physics II</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Home</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/language-model.html" class="sidebar-item-text sidebar-link active">Language Models</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/diffusion.html" class="sidebar-item-text sidebar-link">Diffusion Models</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/hyperspectral_unmixing.html" class="sidebar-item-text sidebar-link">Hyperspectral Unmixing</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/report.html" class="sidebar-item-text sidebar-link">Report</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-is-a-language-model" id="toc-what-is-a-language-model" class="nav-link active" data-scroll-target="#what-is-a-language-model">What is a language model?</a></li>
  <li><a href="#neural-network-based-language-model-types-of-language-models" id="toc-neural-network-based-language-model-types-of-language-models" class="nav-link" data-scroll-target="#neural-network-based-language-model-types-of-language-models">Neural Network-Based Language Model (Types of Language Models)</a></li>
  <li><a href="#training-language-models" id="toc-training-language-models" class="nav-link" data-scroll-target="#training-language-models">Training Language Models</a></li>
  <li><a href="#different-things-models-for-nlp-can-do" id="toc-different-things-models-for-nlp-can-do" class="nav-link" data-scroll-target="#different-things-models-for-nlp-can-do">Different things models for NLP can do!</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/kennethmleo/Physics312/edit/main/content/language-model.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/kennethmleo/Physics312/blob/main/content/language-model.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/kennethmleo/Physics312/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Language Models</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kenneth Leo </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>Language models are an important part of natural language processing (NLP) since they provide a way for computers to process or understand the natural language and to be able to extract information that can be used in different applications. These <strong>natural language</strong> are something that is being used by humans and evolves naturally through repetitive use (speech, sign language, non-verbal cues).</p>
<section id="what-is-a-language-model" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-language-model">What is a language model?</h2>
<p>In its simplest form, a language model is a probability distribution such that, given a sequence of words, a language model will give the probability of all the words being chosen next in the available vocabulary. For example, given a series of words <span class="math inline">\(w_{1:(t-1)} = (w_1,...,w_{t-1})\)</span>, a language model will give us the probability of all words in its vocabulary <span class="math inline">\(V\)</span> to appear next to the series of words <span class="citation" data-cites="Penke_2022b">(<a href="#ref-Penke_2022b" role="doc-biblioref">Penke 2022</a>)</span>. <span class="math display">\[
P(w_t | w_{1:(t-1)}), \ \ \ \ \ \ \ w_1,...,w_{t-1}\in V
\]</span></p>
<p>So if we want our model to complete our sentence, we select the word which has the highest probability and then put that word to the series of words and then use the model again to generate the next word. So the essence of a language model is to simply imitate how a human would respond to different prompts.</p>
<p>To give an idea of what a language model can do, let us look at the ChatGPT, see <a href="#fig-gpt">Figure&nbsp;1</a>, which is an artificial intelligence (AI) chatbot that is developed by OpenAI last November 2022.</p>
<div id="fig-gpt" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures_LLM/chat_gpt_sample.gif" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Example of a language model (ChatGPT)</figcaption><p></p>
</figure>
</div>
<p>We asked the AI to explain quantum computing in simple terms and we see how it was able to provide an extensive discsussion of what quantum computing is. Now, the reason why these AI chatbots are gaining such traction is that it serves as a good starting point when writing or when you want to gain a better understanding of topics that were not discussed properly for example.</p>
</section>
<section id="neural-network-based-language-model-types-of-language-models" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-based-language-model-types-of-language-models">Neural Network-Based Language Model (Types of Language Models)</h2>
<p>ChatGPT is an example of a generative pre-trained transformer (GPT) which is a type of language model that relies on deep learning that generates texts based on a given input text.</p>
</section>
<section id="training-language-models" class="level2">
<h2 class="anchored" data-anchor-id="training-language-models">Training Language Models</h2>
<p>Focusing on the transformer models, we need to know how the neural network model is being trained: including the <em>pre-training</em> and <em>fine-tuning</em> processes. In pre-training process, we provide a general language model that has a good understarding of how language is being used in a variety of settings.</p>
<p>For a neural network, we use <span class="math inline">\(n\)</span> inputs and then it is processed in several hidden layers until it reaches an output layer. Ideally, we want the output of our neural network to be close to the actual/real output. If that is not the case, then we use <strong>gradient descent</strong> to change the parameters to reduce the loss function of our network. In gradient descent, what happens is we use the output and compute some values and then feed it back to our hidden layers until the loss is minimized, which is why the process is also called backpropagation, see <a href="#fig-neural">Figure&nbsp;2</a>.</p>
<div id="fig-neural" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures_LLM/neural_network.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Simplified Neural Network</figcaption><p></p>
</figure>
</div>
<p>One problem of the neural network above is that the input size is fixed and in general, we would want to process input sizes that are longer or shorter. Now in the field of language modelling, there are two types of networks that were considered state of the art: <em>recurrent neural networks</em> and <em>long short-term memory networks</em>.</p>
<section id="recurrent-neural-networks-rnns" class="level4">
<h4 class="anchored" data-anchor-id="recurrent-neural-networks-rnns">Recurrent neural networks (RNNs)</h4>
<p>In a recurrent neural network, we still have the same neural network discussed above to every word in a series of words. Whats different for RNNs is that last word (newest word) in the sequence of words has the most influence in choosing the next word and the probability of influence of previous words reduce exponentially as new words are being introduced. We see in <a href="#fig-rnn">Figure&nbsp;3</a> how RNNs are able to connect information (or words) in a sequential manner.</p>
<div id="fig-rnn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures_LLM/rnn.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Recurring Neural Network <span class="citation" data-cites="Olah_2015">(<a href="#ref-Olah_2015" role="doc-biblioref">Olah 2015</a>)</span></figcaption><p></p>
</figure>
</div>
<p>This makes sense but the problem is, language in itself is more nuanced in the sense that sometimes we need to take into account not only the last word in our sentence but the sentence as a whole <span class="citation" data-cites="Penke_2022b">(<a href="#ref-Penke_2022b" role="doc-biblioref">Penke 2022</a>)</span>. For example, in <a href="#fig-rnn">Figure&nbsp;3</a>, if we need the output <span class="math inline">\(h_{10}\)</span>, the information from the input <span class="math inline">\(x_1\)</span> has very little effect on the output and this might pose a problem if we are for example dealing with a sentence whose subject and verb are very far from each other. Because of this unique feature of language, the concept of older worlds having less influence becomes a bug and is called the <em>vanishing gradients</em> problem</p>
</section>
<section id="long-short-term-memory-lstm-networks" class="level4">
<h4 class="anchored" data-anchor-id="long-short-term-memory-lstm-networks">Long short-term memory (LSTM) networks</h4>
<p>Now LSTMs solve the <em>vanishing gradients</em> problem by introducing a “memory” state whose influence is determined by gates defined by more learnable parameters <span class="citation" data-cites="Penke_2022b">(<a href="#ref-Penke_2022b" role="doc-biblioref">Penke 2022</a>)</span>. The main difference of LSTM fromm RNN is that the former type of network remembers information for long periods of time by default but has there functions, called gates that can either use the information stored to process the output or to “forget” the previous information and not use for the output.</p>
<div id="fig-lstm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures_LLM/lstm.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;4: Long Short-Term Memory Network <span class="citation" data-cites="Olah_2015">(<a href="#ref-Olah_2015" role="doc-biblioref">Olah 2015</a>)</span></figcaption><p></p>
</figure>
</div>
<p>In an LSTM network, there are three gates that are needed to pass through. First is the gate that chooses which information to forget, then the second gate decides which information to store. In the second gate, we have two functions which decides which values will be updated and what values will be used to update. Lastly, the third gate will decide which information will be the output.</p>
<p><em>Drawback of RRN and LSTM</em> Now, while both networks are successful in predicting the next word given a series of words, one major drawback of these two networks is that they require their input data to be processed sequentially, that is in order to process the next word of input <span class="math inline">\(x_i\)</span>, we need the result of the previous input <span class="math inline">\(x_{i-1}\)</span>.</p>
<p>The <em>attention</em> mechanism addresses this issue by stacking the input in a matrix such that they can all be processed at the same time. According to the paper “Attention is all you need” <span class="citation" data-cites="vaswani2017attention">(<a href="#ref-vaswani2017attention" role="doc-biblioref">Vaswani et al. 2017</a>)</span>, the authors defined the attention function as the following:</p>
<p><code>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum  of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</code></p>
<p>Now, the attention mechanism is used in a neural network architecture called a <strong>transformer</strong>.</p>
<p>Here is how the transformer neural network works:</p>
<ol type="1">
<li>Tokenization (Discussion from <span class="citation" data-cites="Howard_Gugger_2021">Howard and Gugger (<a href="#ref-Howard_Gugger_2021" role="doc-biblioref">2021</a>)</span>)</li>
</ol>
<p>Tokenization is the process of converting words or any natural language to tokens which are the ones processed by our computers. There are three main approaches in tokenization which are the following:</p>
<ul>
<li>Word-based: Split a sentence on spaces where generally, punctuation marks are also split into different tokens.</li>
<li>Subword-based: Split words into subwords. Example would be “o c ca sion”.</li>
<li>Character-based: Split sentence into individual characters.</li>
</ul>
<p>For example, taking the sentence “Once again Mr.&nbsp;Costner has dragged out a movie for far longer than necessary.”</p>
<p>Using the <code>fastai</code> module in Python, we can implement the different types of tokenization. For example, for word tokenization, we have the following code and output</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.text.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.IMDB)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>files <span class="op">=</span> get_text_files(path, folders <span class="op">=</span> [<span class="st">'train'</span>, <span class="st">'test'</span>, <span class="st">'unsup'</span>])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> files[<span class="dv">0</span>].<span class="bu">open</span>().read()</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original Sentence:"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(txt[:<span class="dv">77</span>])</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>spacy <span class="op">=</span> WordTokenizer()</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>toks <span class="op">=</span> first(spacy([txt[:<span class="dv">77</span>]]))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Word Tokenization:"</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coll_repr(toks, <span class="dv">30</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Original Sentence:
Once again Mr. Costner has dragged out a movie for far longer than necessary.
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Word Tokenization:
(#15) ['Once','again','Mr.','Costner','has','dragged','out','a','movie','for','far','longer','than','necessary','.']</code></pre>
</div>
</div>
<p>Tokenization is an important step in the neural network architecture since it converts the natural language that we understand to these tokens that can be understood by our machines after converter them to numbers, a process called <strong>Numericalization</strong> which can also be done using the <code>fastai</code> module.</p>
<p>Now that we have the numbers that our computer can process, we can actually now split them into 3 batches: training, validating, and testing batches. We put the training batch in a chosen language model and then validate the results. Now after training our model, we can now actually specify the things that our model can do. In the following chapter, we discuss some of the things that language models can actually do.</p>
</section>
</section>
<section id="different-things-models-for-nlp-can-do" class="level2">
<h2 class="anchored" data-anchor-id="different-things-models-for-nlp-can-do">Different things models for NLP can do!</h2>
<p><strong>Text Classification</strong></p>
<p>There are two types of classification wherein NLP models are very useful for: binary classification and multi-label classification. Binary classification is useful in sentiment analysis where texts can be labeled as something <code>good</code> or <code>bad</code> which can help informed decisions in fields like politics, and marketing. Multi-label classification on the other hand is useful in organizing and filtering tons of information in social media and news for example.</p>
<p><strong>Token Classification</strong></p>
<p>In token classification, we classify the tokens produced after the tokenization process. This is actually useful for example in in labeling tokens specifically those that can be categorized as people or entities that need to be identified. Another thing that this is useful for is for identifying which part of speech certain words/tokens are. We can actually use NLP models to create those tree diagrams where a sentence can be broken down into different part of speeches!</p>
<p><strong>Translation</strong></p>
<p>Of course, a common application of NLP models is for translating a language to another. Language models learns the structure of the input so that it can be able to translate it to another language with the use of transfer learning models. These transfer learning models are actually useful in order to reduce the time it would take the model to train.<br>
</p>
<p><strong>Question Answering</strong></p>
<p>Now, one of the most commonly seen application of language models is this question answering. Siri, Alexa, Bixby, and Google Assistant are examples of some end-user products that uses language model to answer day to day questions of people. And because of the sudden interest of the general public to these language models (ChatGPT for example), many researchers and developers have actually made their pre-trained models open access, which means they are publicly available for non-commercial use. An example of this would be the <code>alpaca.cpp</code> <span class="citation" data-cites="antimatter15_2022">(<a href="#ref-antimatter15_2022" role="doc-biblioref">antimatter15 2022</a>)</span> which makes use of the LLaMA foundation model with some finetuning mechanisms and a couple tweaks to make it into a chat interface. Here is a sample gif of how it works. It’s basically a locally run ChatGPT!</p>
<div id="fig-alpaca" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="alpaca_in_motion.gif" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;5: Example of alpaca.cpp</figcaption><p></p>
</figure>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-antimatter15_2022" class="csl-entry" role="doc-biblioentry">
antimatter15, antimatter15. 2022. <span>“Antimatter15/Alpaca.cpp: Locally Run an Instruction-Tuned Chat-Style LLM.”</span> <em>GitHub</em>. <a href="https://github.com/antimatter15/alpaca.cpp">https://github.com/antimatter15/alpaca.cpp</a>.
</div>
<div id="ref-Howard_Gugger_2021" class="csl-entry" role="doc-biblioentry">
Howard, Jeremy, and Sylvain Gugger. 2021. <span>“Chapter 10, NLP.”</span> In <em>Deep Learning for Coders with FASTAI and Pytorch: AI Applications Without a Phd</em>. O’Reilly Media, Inc.
</div>
<div id="ref-Olah_2015" class="csl-entry" role="doc-biblioentry">
Olah, Christopher. 2015. <span>“Understanding LSTM Networks.”</span> <em>Understanding LSTM Networks – Colah’s Blog</em>. <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>.
</div>
<div id="ref-Penke_2022b" class="csl-entry" role="doc-biblioentry">
Penke, Carolin. 2022. <span>“A Mathematician’s Introduction to Transformers and Large Language Models.”</span> <em>JSC Accelerating Devices Lab</em>. Online. <a href="https://x-dev.pages.jsc.fz-juelich.de/2022/07/13/transformers-matmul.html">https://x-dev.pages.jsc.fz-juelich.de/2022/07/13/transformers-matmul.html</a>.
</div>
<div id="ref-vaswani2017attention" class="csl-entry" role="doc-biblioentry">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention Is All You Need.”</span> <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Home</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../content/diffusion.html" class="pagination-link">
        <span class="nav-page-text">Diffusion Models</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">© CC-1.0</div>   
    <div class="nav-footer-right">This page is built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>